{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are no files to add. Please, make sure you put your files in the correct directory (datasets_list_toadd)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from mljar import extend_dataset, run_automl\n",
    "\n",
    "def df_column_switch(df, column1, column2):\n",
    "    i = list(df.columns)\n",
    "    a, b = i.index(column1), i.index(column2)\n",
    "    i[b], i[a] = i[a], i[b]\n",
    "    df = df[i]\n",
    "    return df\n",
    "\n",
    "def df_fix_target_left(df):\n",
    "    i = df.columns.tolist()\n",
    "    new_i = i[1:] + [i[0]]\n",
    "    df = df[new_i]\n",
    "    return df\n",
    "\n",
    "def df_fix_arbitrary_position_target(df, target_name):\n",
    "    i = df.columns.tolist()\n",
    "    pos = i.index(target_name)\n",
    "    new_i = i[0:pos] + i[pos + 1:] + [i[pos]]\n",
    "    df = df[new_i]\n",
    "    return df\n",
    "\n",
    "def process_left_target_file(dataset_name):\n",
    "    dataset_raw = pd.read_csv('datasets_list_raw/' + dataset_name + '.csv')\n",
    "    dataset_inverted = df_fix_target_left(dataset_raw)\n",
    "    dataset_inverted.to_csv('datasets_list_raw/' + dataset_name + '.csv', index=False)\n",
    "    print(dataset_inverted.columns)\n",
    "\n",
    "def check(dataset_name):\n",
    "    dataset_raw = pd.read_csv('datasets_list_raw/' + dataset_name + '.csv')\n",
    "    print(dataset_raw.columns)\n",
    "\n",
    "def move(dataset_name):\n",
    "    dataset_raw = pd.read_csv('datasets_list_raw/' + dataset_name + '.csv')\n",
    "    dataset_raw.to_csv('datasets_list_toadd/' + dataset_name + '.csv', index=False)\n",
    "\n",
    "def process_fix_arbitrary_position_target_file(dataset_name, target_name):\n",
    "    dataset_raw = pd.read_csv('datasets_list_raw/' + dataset_name + '.csv')\n",
    "    dataset_inverted = df_fix_arbitrary_position_target(dataset_raw, target_name)\n",
    "    dataset_inverted.to_csv('datasets_list_raw/' + dataset_name + '.csv', index=False)\n",
    "    print(dataset_inverted.columns)\n",
    "\n",
    "def process_remove_ID_file(dataset_name):\n",
    "    dataset_raw = pd.read_csv('datasets_list_raw/' + dataset_name + '.csv', index_col=0)\n",
    "    dataset_raw.to_csv('datasets_list_raw/' + dataset_name + '.csv', index=False)\n",
    "    print(dataset_raw.columns)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Titanic (prediction = Survived)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "outputs": [],
   "source": [
    "dataset_raw = pd.read_csv('datasets_list_raw/titanic_raw.csv')\n",
    "dataset_inverted = df_column_switch(dataset_raw, 'Survived', 'Embarked')\n",
    "dataset_inverted.to_csv('datasets_list_final/titanic.csv', index=False)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Higgs (prediction = Prediction)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "outputs": [],
   "source": [
    "dataset_raw = pd.read_csv('datasets_list_raw/higgs_raw.csv')\n",
    "dataset_inverted = df_column_switch(dataset_raw, 'Prediction', 'PRI_jet_all_pt')\n",
    "dataset_inverted.to_csv('datasets_list_final/higgs.csv', index=False)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Hotel (prediction = Hotel)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "outputs": [],
   "source": [
    "dataset_raw = pd.read_csv('datasets_list_raw/hotel_raw.csv')\n",
    "dataset_inverted = df_column_switch(dataset_raw, 'hotel', 'reservation_status_date')\n",
    "dataset_inverted.to_csv('datasets_list_final/hotel.csv', index=False)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Wine (separator)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "outputs": [],
   "source": [
    "dataset_raw_red = pd.read_csv('datasets_list_raw/wine_red_raw.csv', sep=';')\n",
    "dataset_raw_white = pd.read_csv('datasets_list_raw/wine_white_raw.csv', sep=';')\n",
    "dataset_raw_red.to_csv('datasets_list_final/wine_red.csv', index=False)\n",
    "dataset_raw_white.to_csv('datasets_list_final/wine_white.csv', index=False)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# monks-problems (prediction = Class)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "outputs": [],
   "source": [
    "dataset_raw = pd.read_csv('datasets_list_raw/monks_raw.csv')\n",
    "dataset_inverted = df_column_switch(dataset_raw, 'class', 'attr6')\n",
    "dataset_inverted.to_csv('datasets_list_final/monks.csv', index=False)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# cjs (prediction = TR)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "outputs": [],
   "source": [
    "dataset_raw = pd.read_csv('datasets_list_raw/cjs_raw.csv')\n",
    "dataset_inverted = df_column_switch(dataset_raw, 'TR', 'INTERNODE_29')\n",
    "dataset_inverted.to_csv('datasets_list_final/cjs.csv', index=False)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Pipeline for new datasets"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Airline', 'Flight', 'AirportFrom', 'AirportTo', 'DayOfWeek', 'Time',\n",
      "       'Length', 'Delay'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "dataset_name = 'airlines' # put here new dataset name\n",
    "check(dataset_name)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['impression', 'url_hash', 'ad_id', 'advertiser_id', 'depth', 'position',\n",
      "       'query_id', 'keyword_id', 'title_id', 'description_id', 'user_id',\n",
      "       'click'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "process_left_target_file(dataset_name)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "move(dataset_name)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " DATASET airlines.csv: 0 of 1\n",
      "Linear algorithm was disabled.\n",
      "AutoML directory: /home/giovanni/Desktop/ML/CS433-2021-ecoML/prediction_feature/results/airlines\n",
      "The task is binary_classification with evaluation metric f1\n",
      "AutoML will use algorithms: ['Random Forest', 'Decision Tree', 'Neural Network']\n",
      "AutoML will ensemble available models\n",
      "AutoML steps: ['simple_algorithms', 'default_algorithms', 'ensemble']\n",
      "* Step simple_algorithms will try to check up to 1 model\n",
      "1_DecisionTree f1 0.524425 trained in 35.86 seconds\n",
      "* Step default_algorithms will try to check up to 2 models\n",
      "2_Default_NeuralNetwork f1 0.442007 trained in 160.2 seconds\n",
      "3_Default_RandomForest f1 0.510269 trained in 53.02 seconds\n",
      "* Step ensemble will try to check up to 1 model\n",
      "Ensemble f1 0.524425 trained in 8.74 seconds\n",
      "AutoML fit time: 264.55 seconds\n",
      "AutoML best model: 1_DecisionTree\n"
     ]
    }
   ],
   "source": [
    "run_automl()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adding dataset airlines ... successfully added!\n"
     ]
    }
   ],
   "source": [
    "extend_dataset()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from supervised.automl import AutoML\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from contextlib import redirect_stdout\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Models tuned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import tree\n",
    "\n",
    "def decision_tree(df):\n",
    "    X=df[df.columns[:-1]]\n",
    "    y=df[df.columns[-1]]\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)\n",
    "    clf = tree.DecisionTreeClassifier()\n",
    "    clf = clf.fit(X_train, y_train)\n",
    "    return f1_score(y_test, clf.predict(X_test), average='macro')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "def random_forest(df):\n",
    "    X=final_dataset[final_dataset.columns[:-1]]\n",
    "    y=final_dataset[final_dataset.columns[-1]]\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)\n",
    "    #hyperparameter-tuning\n",
    "    # Number of trees in random forest\n",
    "    n_estimators = [int(x) for x in np.linspace(start = 10, stop = 100, num = 100)]\n",
    "\n",
    "    # Maximum number of levels in tree\n",
    "    max_depth = [int(x) for x in np.linspace(1, 20, num = 100)]\n",
    "    max_depth.append(None)\n",
    "\n",
    "    # Minimum number of samples required to split a node\n",
    "    min_samples_split = [2, 5, 10]\n",
    "\n",
    "    # Minimum number of samples required at each leaf node\n",
    "    min_samples_leaf = [1, 2, 4]\n",
    "\n",
    "    # Method of selecting samples for training each tree\n",
    "    bootstrap = [True, False]\n",
    "\n",
    "    # Create the random grid\n",
    "    grid = {'n_estimators': n_estimators,\n",
    "                'max_depth': max_depth,\n",
    "                'min_samples_split': min_samples_split,\n",
    "                'min_samples_leaf': min_samples_leaf,\n",
    "                'bootstrap': bootstrap}\n",
    "\n",
    "    rf = RandomForestClassifier()\n",
    "    rf_cv = RandomizedSearchCV(estimator = rf, param_distributions = grid, cv = 5, random_state=42, scoring='f1_macro')\n",
    "    # Fit the random search model\n",
    "    rf_cv.fit(X_train, y_train)\n",
    "    return f1_score(y_test, rf_cv.best_estimator_.predict(X_test), average='macro')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 kNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "def kNN(df):\n",
    "    X=df[df.columns[:-1]]\n",
    "    y=df[df.columns[-1]]\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)\n",
    "    #hyperparameter-tuning\n",
    "    knn=KNeighborsClassifier()\n",
    "    #Create grid\n",
    "    param_grid = {\"n_neighbors\": np.arange(1, 25)}\n",
    "    knn_cv = GridSearchCV(knn, param_grid, cv=5, scoring='f1_macro')\n",
    "    # Fit the random search model\n",
    "    knn_cv.fit(X_train,y_train)\n",
    "    return f1_score(y_test, knn_cv.best_estimator_.predict(X_test), average='macro')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 GradientBoosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "def gradient_boosting(df):\n",
    "    X=df[df.columns[:-1]]\n",
    "    y=df[df.columns[-1]]\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)\n",
    "\n",
    "    #hyperparameter-tuning\n",
    "    n_estimators = np.arange(1,100)\n",
    "    learning_rate = np.linspace(start=1e-1, stop=1, num=10)\n",
    "    max_depth = np.arange(1,50)\n",
    "\n",
    "    # Create the random grid\n",
    "    grid = {'n_estimators': n_estimators,\n",
    "            'max_depth': max_depth,\n",
    "            'learning_rate': learning_rate}\n",
    "    clf = GradientBoostingClassifier()\n",
    "    clf_cv = RandomizedSearchCV(estimator = clf, param_distributions = grid, cv = 5, random_state=42, scoring='f1_macro')\n",
    "    \n",
    "    # Fit the random search model\n",
    "    clf_cv.fit(X_train, y_train)\n",
    "    return f1_score(y_test, clf_cv.best_estimator_.predict(X_test), average='macro')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 2.5 Neural Networks"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "import numpy as np\n",
    "\n",
    "def neural_network(df):\n",
    "    X=df[df.columns[:-1]]\n",
    "    y=df[df.columns[-1]]\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)\n",
    "\n",
    "    # Create the random grid\n",
    "    grid = [\n",
    "    {'solver': ['adam', 'sgd'],\n",
    "     'learning_rate_init': [0.0001],\n",
    "     'max_iter': [10000],\n",
    "     'hidden_layer_sizes': [(50, 40), (40, 40), (30, 30), (20, 20)],\n",
    "     'activation': ['logistic', 'tanh', 'relu'],\n",
    "     'alpha': [0.0001, 0.001, 0.005],\n",
    "     'early_stopping': [True, False]\n",
    "     }\n",
    "]\n",
    "    clf = MLPClassifier()\n",
    "    clf_cv = RandomizedSearchCV(estimator = clf, param_distributions = grid, cv = 5, random_state=42, scoring='f1_macro')\n",
    "\n",
    "    # Fit the random search model\n",
    "    clf_cv.fit(X_train, y_train)\n",
    "    return f1_score(y_test, clf_cv.best_estimator_.predict(X_test), average='macro')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 2.6 Dummy Classifier"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "from sklearn.dummy import DummyClassifier\n",
    "\n",
    "\n",
    "def dummy_classifier(df):\n",
    "    X=df[df.columns[:-1]]\n",
    "    y=df[df.columns[-1]]\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)\n",
    "\n",
    "    clf = DummyClassifier()\n",
    "    clf.fit(X_train, y_train)\n",
    "    return f1_score(y_test, clf.predict(X_test), average='macro')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.Creating dataset with different functions and test models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Function definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def df_column_switch(df, column1, column2):\n",
    "    i = list(df.columns)\n",
    "    a, b = i.index(column1), i.index(column2)\n",
    "    i[b], i[a] = i[a], i[b]\n",
    "    df = df[i]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "a=1.5\n",
    "b=3\n",
    "def function_log_exp(x,y):\n",
    "    return (np.exp(a*x))/((1/a)*np.log(y+1))\n",
    "def function_log_power(x,y):\n",
    "    return (np.power(x,b))/(np.log(y+1))\n",
    "def function_log(x,y):\n",
    "    return x/(np.log(y+1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_final_dataset(df, function):\n",
    "    #compute value\n",
    "    df['value'] = function(df['F1'], df['time'])\n",
    "    df = df.drop(columns=['F1', 'time', 'consumption','TDP', 'country'])\n",
    "    #keep most green entry for each dataset\n",
    "    final_dataset = df.sort_values('value').drop_duplicates(df.columns[:-2],keep='last')\n",
    "    final_dataset = df_column_switch(final_dataset, 'algo', 'value')\n",
    "    final_dataset = final_dataset.drop(columns = ['value'])\n",
    "    return final_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_autoML(df):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(df[df.columns[:-1]], df[df.columns[-1]], test_size=0.25)\n",
    "    automl = AutoML(eval_metric='f1', explain_level=1, top_models_to_improve=4, random_state=2, optuna_verbose=False)\n",
    "    automl.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Selecting best function for evaluating \"greenness\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dataset = pd.read_csv('ml_dataset.csv')\n",
    "dataset_cleaned  = dataset[dataset.algo != 'Ensemble']\n",
    "dataset_cleaned = dataset_cleaned.drop(columns=['did'])\n",
    "dataset_cleaned['consumption']=dataset_cleaned['time']*dataset_cleaned['TDP']\n",
    "\n",
    "list_functions=[function_log_exp, function_log_power, function_log]\n",
    "list_models=[{\"name\":\"decision tree\", \"clf\":decision_tree}, {\"name\":\"kNN\", \"clf\":kNN}, {\"name\":\"random forest\", \"clf\":random_forest},{\"name\":\"gradient boosting\",  \"clf\":gradient_boosting}, {\"name\":\"neural network\", \"clf\":neural_network}, {\"name\":\"dummy\", \"clf\":dummy_classifier}]\n",
    "#list_models=[{\"name\":\"NN\", \"clf\":neural_network}]\n",
    "names=[x['name'] for x in list_models]\n",
    "average_f1=[]\n",
    "# with open('out.txt', 'w') as f:\n",
    "#     with redirect_stdout(f):\n",
    "for i,function in enumerate(list_functions):\n",
    "    # run_autoML(final_dataset)\n",
    "    f1_scores=[]\n",
    "    print(f'STEP {i} ------h------------------------------------------------------------------ ')\n",
    "    dataset_cleaned_copy=dataset_cleaned.copy()\n",
    "    final_dataset=compute_final_dataset(dataset_cleaned_copy, function)\n",
    "    \n",
    "    #drop na\n",
    "    final_dataset=final_dataset.dropna()\n",
    "    #min-max normalization\n",
    "    #final_dataset[features]=(final_dataset[features]-final_dataset[features].min())/(final_dataset[features].max()-final_dataset[features].min())\n",
    "    for model in list_models:\n",
    "        f1_scores.append(model['clf'](final_dataset))\n",
    "    plt.ylabel(\"F1 Score\")\n",
    "    plt.xlabel(\"Model Used\")\n",
    "    plt.bar(names, f1_scores)\n",
    "    plt.show()\n",
    "    print(f'Max F1-score: {np.max(np.array(f1_scores))}')\n",
    "    average_f1.append(np.mean(np.array(f1_scores)))\n",
    "    \n",
    "print(f'FINAL')\n",
    "plt.ylabel(\"Average F1 Score\")\n",
    "plt.xlabel(\"Function group Used\")\n",
    "names=[f'Group {i}°' for i in range(len(list_functions))]\n",
    "plt.bar(names, average_f1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Compute features for new dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STEP 0 ----------------------------------------------------------------------- \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         7\n",
      "           1       0.57      0.55      0.56       109\n",
      "           2       0.25      0.32      0.28        47\n",
      "           3       0.41      0.38      0.40        60\n",
      "\n",
      "    accuracy                           0.44       223\n",
      "   macro avg       0.31      0.31      0.31       223\n",
      "weighted avg       0.44      0.44      0.44       223\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         7\n",
      "           1       0.52      0.70      0.60       109\n",
      "           2       0.35      0.28      0.31        47\n",
      "           3       0.46      0.32      0.38        60\n",
      "\n",
      "    accuracy                           0.48       223\n",
      "   macro avg       0.33      0.32      0.32       223\n",
      "weighted avg       0.45      0.48      0.46       223\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.14      0.25         7\n",
      "           1       0.59      0.79      0.67       109\n",
      "           2       0.32      0.23      0.27        47\n",
      "           3       0.52      0.37      0.43        60\n",
      "\n",
      "    accuracy                           0.54       223\n",
      "   macro avg       0.61      0.38      0.41       223\n",
      "weighted avg       0.53      0.54      0.51       223\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.25      0.14      0.18         7\n",
      "           1       0.58      0.75      0.65       109\n",
      "           2       0.33      0.28      0.30        47\n",
      "           3       0.43      0.27      0.33        60\n",
      "\n",
      "    accuracy                           0.50       223\n",
      "   macro avg       0.40      0.36      0.37       223\n",
      "weighted avg       0.47      0.50      0.48       223\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         7\n",
      "           1       0.48      0.56      0.52       109\n",
      "           2       0.24      0.13      0.17        47\n",
      "           3       0.38      0.45      0.41        60\n",
      "\n",
      "    accuracy                           0.42       223\n",
      "   macro avg       0.27      0.28      0.27       223\n",
      "weighted avg       0.39      0.42      0.40       223\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         7\n",
      "           1       0.49      1.00      0.66       109\n",
      "           2       0.00      0.00      0.00        47\n",
      "           3       0.00      0.00      0.00        60\n",
      "\n",
      "    accuracy                           0.49       223\n",
      "   macro avg       0.12      0.25      0.16       223\n",
      "weighted avg       0.24      0.49      0.32       223\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n"
     ]
    },
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max F1-score: 0.4068718228031954\n",
      "STEP 1 ----------------------------------------------------------------------- \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.08      0.07      0.07        15\n",
      "           1       0.57      0.48      0.52        92\n",
      "           2       0.26      0.30      0.28        40\n",
      "           3       0.49      0.57      0.52        76\n",
      "\n",
      "    accuracy                           0.45       223\n",
      "   macro avg       0.35      0.35      0.35       223\n",
      "weighted avg       0.45      0.45      0.45       223\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.25      0.07      0.11        15\n",
      "           1       0.55      0.65      0.60        92\n",
      "           2       0.24      0.23      0.23        40\n",
      "           3       0.53      0.51      0.52        76\n",
      "\n",
      "    accuracy                           0.49       223\n",
      "   macro avg       0.39      0.36      0.36       223\n",
      "weighted avg       0.47      0.49      0.47       223\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        15\n",
      "           1       0.64      0.63      0.63        92\n",
      "           2       0.32      0.23      0.26        40\n",
      "           3       0.53      0.68      0.59        76\n",
      "\n",
      "    accuracy                           0.53       223\n",
      "   macro avg       0.37      0.38      0.37       223\n",
      "weighted avg       0.50      0.53      0.51       223\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.08      0.07      0.07        15\n",
      "           1       0.60      0.49      0.54        92\n",
      "           2       0.33      0.40      0.36        40\n",
      "           3       0.49      0.57      0.52        76\n",
      "\n",
      "    accuracy                           0.47       223\n",
      "   macro avg       0.38      0.38      0.38       223\n",
      "weighted avg       0.48      0.47      0.47       223\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        15\n",
      "           1       0.52      0.64      0.58        92\n",
      "           2       0.28      0.30      0.29        40\n",
      "           3       0.43      0.38      0.41        76\n",
      "\n",
      "    accuracy                           0.45       223\n",
      "   macro avg       0.31      0.33      0.32       223\n",
      "weighted avg       0.41      0.45      0.43       223\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        15\n",
      "           1       0.41      1.00      0.58        92\n",
      "           2       0.00      0.00      0.00        40\n",
      "           3       0.00      0.00      0.00        76\n",
      "\n",
      "    accuracy                           0.41       223\n",
      "   macro avg       0.10      0.25      0.15       223\n",
      "weighted avg       0.17      0.41      0.24       223\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEGCAYAAAB/+QKOAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8QVMy6AAAACXBIWXMAAAsTAAALEwEAmpwYAAAd4UlEQVR4nO3de5gdVZnv8e/P5irIvb1MCCRgFMPIRRpQgcgolzgqQQ8MwfEMeDhm8BhhdPSIB58AGZnhch511DgSNQfvEUU9LUYBuapc7A4Jl4TJoQlBEn00Aga5JYS854+1mlR2Vu/e3elKN92/z/P001WrVlW9Vbt2vbtW1V5bEYGZmVmjlwx3AGZmNjI5QZiZWZEThJmZFTlBmJlZkROEmZkVbTPcAQyVvfbaKyZMmDDcYZiZvagsXLjwTxHRXpo2ahLEhAkT6O7uHu4wzMxeVCQ93Nc0NzGZmVmRE4SZmRU5QZiZWZEThJmZFTlBmJlZkROEmZkVOUGYmVmRE4SZmRU5QZiZWdGo+Sa12YvNhPN+OtwhtGTFJe8Y7hBsmDhB2IuGT6hmW5ebmMzMrMgJwszMipwgzMysyPcgRim315vZlvIVhJmZFTlBmJlZkROEmZkVOUGYmVlRrQlC0lRJyyT1SDqvMP1sSfdKWizpV5Im5/IJkp7J5YslfbnOOM3MbHO1PcUkqQ2YAxwPrAS6JHVGxNJKte9ExJdz/ZOAzwBT87QHI+KQuuIzM7Pm6ryCOALoiYjlEbEOmA9Mq1aIiCcqozsBUWM8ZmY2AHUmiHHAI5XxlblsE5I+JOlB4DLgnMqkiZIWSbpF0jE1xmlmZgXD/kW5iJgDzJH0XuBTwBnA74F9IuJRSYcBP5Z0YMMVB5JmADMA9tlnny2Kw18sMzPbVJ1XEKuA8ZXxvXNZX+YDJwNExNqIeDQPLwQeBF7TOENEzI2IjojoaG9vH6q4zcyMehNEFzBJ0kRJ2wHTgc5qBUmTKqPvAB7I5e35JjeS9gMmActrjNXMzBrU1sQUEeslzQSuBdqAeRGxRNJsoDsiOoGZko4DngMeJzUvAUwBZkt6DtgAnB0Rj9UVq5mZba7WexARsQBY0FA2qzJ8bh/zXQ1cXWdsZmbWnL9JbWZmRU4QZmZW5ARhZmZFThBmZlbkBGFmZkVOEGZmVuQEYWZmRU4QZmZW5ARhZmZFThBmZlbkBGFmZkVOEGZmVuQEYWZmRcP+i3JmNnr4lxlHF19BmJlZkROEmZkVOUGYmVmRE4SZmRU5QZiZWVGtCULSVEnLJPVIOq8w/WxJ90paLOlXkiZXpn0yz7dM0ol1xmlmZpurLUFIagPmAG8HJgOnVxNA9p2IeH1EHAJcBnwmzzsZmA4cCEwFvpSXZ2ZmW0mdVxBHAD0RsTwi1gHzgWnVChHxRGV0JyDy8DRgfkSsjYiHgJ68PDMz20rq/KLcOOCRyvhK4MjGSpI+BHwU2A54a2XeOxrmHVeYdwYwA2CfffYZkqDNzCwZ9pvUETEnIvYHPgF8aoDzzo2IjojoaG9vrydAM7Mxqs4EsQoYXxnfO5f1ZT5w8iDnNTOzIVZngugCJkmaKGk70k3nzmoFSZMqo+8AHsjDncB0SdtLmghMAn5TY6xmZtagtnsQEbFe0kzgWqANmBcRSyTNBrojohOYKek44DngceCMPO8SSVcBS4H1wIci4vm6YjUzs83V2ptrRCwAFjSUzaoMn9tk3ouBi+uLzszMmhn2m9RmZjYyOUGYmVmRE4SZmRU5QZiZWZEThJmZFTlBmJlZkROEmZkVOUGYmVmRE4SZmRU5QZiZWZEThJmZFTlBmJlZkROEmZkVOUGYmVmRE4SZmRU5QZiZWZEThJmZFTlBmJlZkROEmZkV1ZogJE2VtExSj6TzCtM/KmmppHsk3SBp38q05yUtzn+ddcZpZmab26auBUtqA+YAxwMrgS5JnRGxtFJtEdAREU9L+iBwGXBanvZMRBxSV3xmZtZcnVcQRwA9EbE8ItYB84Fp1QoRcVNEPJ1H7wD2rjEeMzMbgDoTxDjgkcr4ylzWl7OAn1XGd5DULekOSSeXZpA0I9fpXr169RYHbGZmG9XWxDQQkt4HdABvqRTvGxGrJO0H3Cjp3oh4sDpfRMwF5gJ0dHTEVgvYzGwMqPMKYhUwvjK+dy7bhKTjgPOBkyJibW95RKzK/5cDNwOH1hirmZk1qDNBdAGTJE2UtB0wHdjkaSRJhwJXkJLDHyvlu0vaPg/vBRwFVG9um5lZzWprYoqI9ZJmAtcCbcC8iFgiaTbQHRGdwOXAzsD3JQH8NiJOAl4HXCFpAymJXdLw9JOZmdWs1nsQEbEAWNBQNqsyfFwf890GvL7O2MzMrDl/k9rMzIqcIMzMrMgJwszMilpKEJKOlvT+PNwuaWK9YZmZ2XDrN0FIugD4BPDJXLQt8K06gzIzs+HXyhXEu4GTgKcAIuJ3wMvqDMrMzIZfKwliXUQEEACSdqo3JDMzGwlaSRBXSboC2E3SB4BfAF+pNywzMxtuTb8op/T15u8BBwBPAK8FZkXE9VshNjMzG0ZNE0REhKQFEfF6wEnBzGwMaaWJ6S5Jh9ceiZmZjSit9MV0JPD3kh4mPckk0sXFQbVGZmZmw6qVBHFi7VGYmdmI028TU0Q8DOwGvCv/7ZbLzMxsFGvlm9TnAt8GXp7/viXpw3UHZmZmw6uVJqazgCMj4ikASZcCtwNfqDMwMzMbXq08xSTg+cr487nMzMxGsVauIP4PcKekH+Xxk4Gv1RaRmZmNCK3cpP4M8H7gsfz3/oj4XCsLlzRV0jJJPZLOK0z/qKSlku6RdIOkfSvTzpD0QP47o+UtMjOzIdHvFYSkNwJLIuKuPL6LpCMj4s5+5msD5gDHAyuBLkmdEbG0Um0R0BERT0v6IHAZcJqkPYALgA5SJ4EL87yPD2IbzcxsEFq5B/EfwJOV8SdzWX+OAHoiYnlErAPmA9OqFSLipoh4Oo/eAeydh08Ero+Ix3JSuB6Y2sI6zcxsiLR0kzp39w1ARGygtXsX44BHKuMrc1lfzgJ+NpB5Jc2Q1C2pe/Xq1S2EZGZmrWolQSyXdI6kbfPfucDyoQxC0vtIzUmXD2S+iJgbER0R0dHe3j6UIZmZjXmtJIizgTcDq/LfkcCMFuZbBYyvjO+dyzYh6TjgfOCkiFg7kHnNzKw+/TYVRcQfgemDWHYXMEnSRNLJfTrw3moFSYcCVwBT83p6XQv8q6Td8/gJbPxNbDMz2wr6vIKQ9AFJk/KwJM2TtCY/kvqG/hYcEeuBmaST/f3AVRGxRNJsSSflapcDOwPfl7RYUmee9zHgX0hJpguYncvMzGwraXYFcS5wZR4+HTgY2A84FPh34Jj+Fh4RC4AFDWWzKsPHNZl3HjCvv3WYmVk9mt2DWB8Rz+XhdwLfiIhHI+IXwE71h2ZmZsOpWYLYIOlVknYA3gb8ojJtx3rDMjOz4dasiWkW0A20AZ0RsQRA0lsY4sdczcxs5OkzQUTENblvpJc1dHHRDZxWe2RmZjasmj7mmp9Eeryh7KlaIzIzsxGhlS/KmZnZGOQEYWZmRYNKEJIOGOpAzMxsZBnsFcR1QxqFmZmNOH3epJb0+b4mAbvVEo2ZmY0YzZ5iej/wz8DawrTT6wnHzMxGimYJogu4LyJua5wg6cLaIjIzsxGhWYI4BXi2NCEiJtYTjpmZjRTNblLvXPm9aDMzG2OaJYgf9w5Iurr+UMzMbCRpliBUGd6v7kDMzGxkaZYgoo9hMzMbA5rdpD5Y0hOkK4kd8zB5PCJil9qjMzOzYdOsu++2rRmImZmNLLV21idpqqRlknoknVeYPkXSXZLWSzqlYdrzkhbnv8464zQzs801/T2ILSGpDZgDHA+sBLokdUbE0kq13wJnAh8rLOKZiDikrvjMzKy52hIEcATQExHLASTNB6YBLySIiFiRp22oMQ4zMxuEOpuYxgGPVMZX5rJW7SCpW9Idkk4uVZA0I9fpXr169RaEamZmjUbyDwbtGxEdwHuBz0nav7FCRMyNiI6I6Ghvb9/6EZqZjWJ1NjGtAsZXxvfOZS2JiFX5/3JJNwOHAg8OZYBmZs1MOO+nwx1CS1Zc8o5allvnFUQXMEnSREnbAdOBlp5GkrS7pO3z8F7AUVTuXZiZWf1qSxARsR6YCVwL3A9cFRFLJM2WdBKApMMlrQROBa6QtCTP/jqgW9LdwE3AJQ1PP5mZWc3qbGIiIhYACxrKZlWGu0hNT43z3Qa8vs7YzMysuZF8k9rMzIaRE4SZmRU5QZiZWZEThJmZFTlBmJlZkROEmZkVOUGYmVmRE4SZmRU5QZiZWZEThJmZFTlBmJlZkROEmZkVOUGYmVmRE4SZmRU5QZiZWZEThJmZFTlBmJlZkROEmZkV1ZogJE2VtExSj6TzCtOnSLpL0npJpzRMO0PSA/nvjDrjNDOzzdWWICS1AXOAtwOTgdMlTW6o9lvgTOA7DfPuAVwAHAkcAVwgafe6YjUzs83VeQVxBNATEcsjYh0wH5hWrRARKyLiHmBDw7wnAtdHxGMR8ThwPTC1xljNzKxBnQliHPBIZXxlLqt7XjMzGwIv6pvUkmZI6pbUvXr16uEOx8xsVKkzQawCxlfG985lQzZvRMyNiI6I6Ghvbx90oGZmtrk6E0QXMEnSREnbAdOBzhbnvRY4QdLu+eb0CbnMzMy2ktoSRESsB2aSTuz3A1dFxBJJsyWdBCDpcEkrgVOBKyQtyfM+BvwLKcl0AbNzmZmZbSXb1LnwiFgALGgom1UZ7iI1H5XmnQfMqzM+MzPr24v6JrWZmdXHCcLMzIqcIMzMrMgJwszMipwgzMysyAnCzMyKnCDMzKzICcLMzIqcIMzMrMgJwszMipwgzMysyAnCzMyKnCDMzKzICcLMzIqcIMzMrMgJwszMipwgzMysyAnCzMyKnCDMzKyo1gQhaaqkZZJ6JJ1XmL69pO/l6XdKmpDLJ0h6RtLi/PflOuM0M7PNbVPXgiW1AXOA44GVQJekzohYWql2FvB4RLxa0nTgUuC0PO3BiDikrvjMzKy5Oq8gjgB6ImJ5RKwD5gPTGupMA76eh38AvE2SaozJzMxaVGeCGAc8UhlfmcuKdSJiPbAG2DNPmyhpkaRbJB1TWoGkGZK6JXWvXr16aKM3MxvjRupN6t8D+0TEocBHge9I2qWxUkTMjYiOiOhob2/f6kGamY1mdSaIVcD4yvjeuaxYR9I2wK7AoxGxNiIeBYiIhcCDwGtqjNXMzBrUmSC6gEmSJkraDpgOdDbU6QTOyMOnADdGREhqzze5kbQfMAlYXmOsZmbWoLanmCJivaSZwLVAGzAvIpZImg10R0Qn8DXgm5J6gMdISQRgCjBb0nPABuDsiHisrljNzGxztSUIgIhYACxoKJtVGX4WOLUw39XA1XXGZmZmzY3Um9RmZjbMnCDMzKzICcLMzIqcIMzMrMgJwszMipwgzMysyAnCzMyKnCDMzKzICcLMzIqcIMzMrMgJwszMipwgzMysyAnCzMyKnCDMzKzICcLMzIqcIMzMrMgJwszMipwgzMysyAnCzMyKak0QkqZKWiapR9J5henbS/penn6npAmVaZ/M5csknVhnnGZmtrnaEoSkNmAO8HZgMnC6pMkN1c4CHo+IVwOfBS7N804GpgMHAlOBL+XlmZnZVlLnFcQRQE9ELI+IdcB8YFpDnWnA1/PwD4C3SVIunx8RayPiIaAnL8/MzLaSbWpc9jjgkcr4SuDIvupExHpJa4A9c/kdDfOOa1yBpBnAjDz6pKRlQxP6kNkL+NNQLlCXDuXSBmy0bQ+Mvm0abdsDo2+bRtr27NvXhDoTRO0iYi4wd7jj6Iuk7ojoGO44hspo2x4Yfds02rYHRt82vZi2p84mplXA+Mr43rmsWEfSNsCuwKMtzmtmZjWqM0F0AZMkTZS0Hemmc2dDnU7gjDx8CnBjREQun56fcpoITAJ+U2OsZmbWoLYmpnxPYSZwLdAGzIuIJZJmA90R0Ql8DfimpB7gMVISIde7ClgKrAc+FBHP1xVrjUZs89cgjbbtgdG3TaNte2D0bdOLZnuUPrCbmZltyt+kNjOzIicIMzMrGjMJQtKFkj42yHlv62f6Akm7DSqwTZdzcuHb5luFpAmS7msoO1ZSSHpXpewaScfm4ZsldVemdUi6eSuFXI1zhaS9aljudyXdI+kjQ7zcFZL2yvv33i1YzpmS/qqPaTdLquVRynysvLcy3iHp81uwvCF5/fL+fPOWLqew3DMlfbFQPuhzyovFmEkQWyIimh50EfG3EfHnIVjVyaRuSTaTHwMeDiuB85tMf7mktw9mwUpG5DEo6ZXA4RFxUER8toX62wziNTqWjT0JDMaZQDFB1GwC8EKCiIjuiDinr8pb8dg9FhjSBDGM77sRYUS+OYeKpPMl/T9JvwJeWynfX9LPJS2U9EtJB+TyV0j6kaS789+bc/mT+f+rJN0qabGk+yQdk8tf+AQk6aN52n2S/imXTZB0v6SvSFoi6TpJOzbE+mbgJODyvPz986fAz+VP6edKOkzSLTnuayW9qtn2bMF+20/SIuBw4G5gjaTj+6h+Oc0TSOOyJyh1wPgN4D5gvKT/kNSd981FlborJF0k6S5J91Zepz3zPlwi6auAKvP0tf//U9KV+Xj4tqTjJP1a0gOSSt24XAeMy6/FV3MsT0j6c45l9/z6rJT0B+Ah4Io87S+57k35mNkzr/9ZSY8B7aTv+ZwNXJbXcYykj0vqUrpquagS+2bHjqRTgA7g23n+HQvb8F8rx+oReXl7SPpxXscdkg6qlF+XY/yDUkeZ10k6Pi9jad6mRaTH0N+Sy38j6QJJ1+TlrJM0L097RukKaWmedn9e/lN5vqafviU9KelipffiHZJekcvbJV2d91WXpKOUOvo8G/hIXvdbJD2kZDdJz0uakue/VdKkJvviQknflPRr4JsNMX09b9cd5HOKKldrSleGK/LwmXn51+fjZ2Y+Phfl9e1Rmf+zSu+B+yUdLumH+dj8dK4zW/l4zuMXSzq32f4bEhExKv+Aw4B7gZcCu5D6c/pYnnYDMCkPH0n6/gXA94B/ysNtwK55+Mn8/5+B8yvTX5aHV5C+Pt+7zp2AnYElwKGkT1zrgUNy/auA9xVivhI4pTJ+M/ClPLwtcBvQnsdPIz063Of2DHB/TSCdsF8LLAIOJn0iuwaYAtyS610DHFuJrwO4EfibPHxzC+vZALyxUrZHZZ/eDBxU2a8fzsP/A/hqHv48MCsPvwOIFvf/60kfihYC80iJZRrw4yb743BgcV7uVOAB4HrgcznWVZXXqL33NQL+e95X83K8TwDbN8R7IbA2z3sC6fFH5Rh793tv7JsdO737v4/9fDPwlTw8BbgvD38BuCAPvxVYXCn/bF7XB/I2XwXcBRxFOsYOJj0a/0HgT5Vj9gLgmjy+Lu+D44GngMdJx+7heR/ukPfP2spruALYq7ANAbwrD18GfCoPfwc4Og/vA9yfhy8kv8fz+M9JHX6+k/S9rPPza/BQP/viQtIxsmMePxP4Iun9/xTpqu2Fc0r1dciv64rKfD3Ay/I2rwHOztM+y8Zzzc3ApXn4XOB3wKtyrCtJ3Q9NAO7KdV4CPAjsWfd5dDRfPh0D/CgingaQ1Jn/70y6DP2+9MIHz+3z/7cC/wAQ6XsXaxqW2QXMk7Qt6aSyuGH60XmdT+V1/TDH0Uk6KHvrLyS94K34Xv7/WuCvgetz3G3A7/vZnoFqB/4v8J6IWKp8ryEibpWEpKP7mO/TwKeAT7S4nocjotrX1t8p9au1DemNMRm4J0/7Yf6/EHhPHp7SOxwRP5X0eC7vb//fm8uXADdERORPuBOaxHoU6UTz3oj4uaSfkE5uJ5JO+n9k42t0NKlTyd+STvTPAbcDLycl3W8DPyadNBudkP8W5fGdSV8Q/S2DP3a+Cy+8frso3Sc7GvgvufxGpaubXXL5OcA7I+IrkmaREuSupGR4MOnE/FyOrdkx9tNc7zfAK4FXkPbjo8CdlXr93XdYR0qUkLa79yr2OGBy5XjfJb8PGv2SdKxMBP6NlPhuIb2Poe99AdAZEc9UlvVW0ofNL0TE72DjOaUfN0XEX4C/KPU195Ncfi9wUKVeZ6V8SUT8Pq9jOTA+IhZLelTSoaT9uSgiHm1h/VtkNCeIvrwE+HNEHDLQGfMbbQrpU+CVkj4TEd9ocfa1leHngVKTQMlT+b9IB86bqhPzAT2o7SlYQzohHU1uFqi4mJQE1jfOlN9cnwbe2OJ6ercJpW/Kf4zU3v+4pCtJnzJ79e6359my47W6/zdUxjds4XI3sHF7/hepB+MDcnK9MCJOkLSY1LX9eOBdpJNuY/f1Av4tIq7YpDA1nQz22Gn8klMrX3pqXNftpAR5HSkxnEg66fc2D63PsaN0P6mtsoyn2Pi6vRrYDzggIp6W9AjpyqKZ5yJ/ZGbT1/8lpCvQZ6uVKwmj162kq52/AmYBHyddFf+yn/X2xl71IOkKec9C3fVsbK7foWFaq8fd2kKdxnpfJV2VvJJ0ZVq70XwP4lbgZKX22peR3phExBPAQ5JOhRdulB6c57mBdEAhqU3SrtUFStoX+ENEfIX0Yr2hYZ2/zOt8qaSdgHfT2sHY6y+ky9GSZUC7pDflWLaVdGA/2zNQ63LM/6DKUyoAEXEdsDubfuqp+jTwPwexzl1Ib8Y1uY25lRvet5JvkirdIN89l2/p/i/5NemT/Z8lnUBqrjiM9Em00bbATvk1OiOFpwNzvGdHxE2k5riXkJrB/sLG+yfXAv+t95OwpHGSXt5PbM2OF0jNkL1XfmsiYg1pf/x9Lj+W1FT0RC4/uVpOOlHtnq/27iM1fRyQ1/vKvI4VwGvy8En0fU55iPRab5D0Bgq9Mw/AdcCHe0ckHZIHG/fHb0hX1xtyMlkM/CPp9YC+90XJw8CHSPd13lA9p5D2wWF5+JTBbVJLfkRq5jycdLzUbtQmiIi4i3TpfzfwMzZeVkI6KM6SdDepnbr3dyrOBf4mNzssZPMnio4F7la6UXca8O+FdV5JOjDvJLWZL6J184GP55tY+zcsex3p4Ls0x72YjU9s9LU9A5abZ94JfIT0hq66mE07UazOtwBYPYj13U1qVvlPUhPGr1uY7SJgSm4qeg/pqmco9n8pvi7S5f+upN8seQWpKW52ofoFpBP+daSrzA7Sa3Qx6fV5FvgG8GdS89RPgLZ8hfEMaftvz8ffD2h+8oe0rV9W3zepn83H6pdJVzCQ2tcPk3QPcAkb+0K7kHSP5tUN5W9Uevx5d1K30LNJN273yMebgENITTlvIjUtlXyRdHysyfvnUeDJfravL+cAHUo3l5eSbk5D2p/vzvvjmIhYS/o5gd7mzF+S9mnvo8UXUt4XRRHxQ9IHw9uBm9h4TvnfwAfzvh7yx60r61+X13tVbKWuh9zVhlk/JO0cEU9Keinp0+eMnIxsALwft0xuwrsLODUiHtga6xyL9yDMBmqu0hcYdwC+7pPaoHk/DlLeb9eQHsLYKskBfAVhZmZ9GLX3IMzMbMs4QZiZWZEThJmZFTlB2Jik1Evttyrj20hardyn0ACW029PpH3VUe7jqzJe7DV0oJT6nKrzeXwbI5wgbKx6CvjryvcHjif1q2RmmROEjWULSF9oAzid3HcRNO31tFlPsu9T6qV0saQrJDV2p9EySacq9cJ6t6Rbc1mbpMu1scfXf8zlkvRFpV5yf0Hq+8lsizlB2Fg2H5guaQdSFyLVjuQuInWIdhCpj6XePrcuAH4VEQeSuj7YB0DS60jfrj8q94v1PLkbh0GaBZwYEQeTurCA9G3oNRFxOKm7hQ8o9WX1blJnjpNJnU0O+Y/m2NjkL8rZmBUR9yh1hnc66Wqiqq+ePvvqSfZtpP54upQ6jduR1NPrgMPK/39N6hDyKjb2aHsCcFDl/sKupB5fpwDfzd0v/E7SjYNYr9lmnCBsrOsk9aVzLOWeOlsl0reDPzmAeZ6RtF3uYwdgD1IneUTE2ZKOJDWBLZR0WF7HhyNik47aJP3tFsRt1ic3MdlYNw+4qPe3Iir66umzr55kbwBO6e2BNd/D2Lefdd8CvC/X3xH4O1JnbEjaPyLujIhZpE7uxpN68Pyg0u+RIOk1udfaW4HT8j2KV5F+vMlsi/kKwsa0iFhJ+sW3RheSfhzqHuBpNvb0eRHw3dyT7G1s7El2qaRPAdflTtWeI3UP/XCT1Z9L+pnSc0hXB9+IiN6uqC+XNCmX30Dqlfge8i+LKbVjrSZ10f0j0g/aLM3x3D6wvWBW5r6YzMysyE1MZmZW5ARhZmZFThBmZlbkBGFmZkVOEGZmVuQEYWZmRU4QZmZW9P8BxtC4qvpgVf4AAAAASUVORK5CYII=\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max F1-score: 0.3752557093253748\n",
      "STEP 2 ----------------------------------------------------------------------- \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.25      0.14      0.18        14\n",
      "           1       0.60      0.64      0.62       104\n",
      "           2       0.26      0.37      0.31        38\n",
      "           3       0.59      0.45      0.51        67\n",
      "\n",
      "    accuracy                           0.51       223\n",
      "   macro avg       0.43      0.40      0.41       223\n",
      "weighted avg       0.52      0.51      0.51       223\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        14\n",
      "           1       0.56      0.77      0.65       104\n",
      "           2       0.27      0.16      0.20        38\n",
      "           3       0.57      0.37      0.45        67\n",
      "\n",
      "    accuracy                           0.50       223\n",
      "   macro avg       0.35      0.33      0.32       223\n",
      "weighted avg       0.48      0.50      0.47       223\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        14\n",
      "           1       0.59      0.88      0.71       104\n",
      "           2       0.30      0.18      0.23        38\n",
      "           3       0.63      0.43      0.51        67\n",
      "\n",
      "    accuracy                           0.57       223\n",
      "   macro avg       0.38      0.37      0.36       223\n",
      "weighted avg       0.52      0.57      0.52       223\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "\u001B[0;32m<ipython-input-14-b149480d9cae>\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m     18\u001B[0m     \u001B[0;31m#final_dataset[features]=(final_dataset[features]-final_dataset[features].min())/(final_dataset[features].max()-final_dataset[features].min())\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     19\u001B[0m     \u001B[0;32mfor\u001B[0m \u001B[0mmodel\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mlist_models\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 20\u001B[0;31m         \u001B[0mf1_scores\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mappend\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mmodel\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;34m'clf'\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mfinal_dataset\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     21\u001B[0m     \u001B[0mplt\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mylabel\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m\"F1 Score\"\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     22\u001B[0m     \u001B[0mplt\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mxlabel\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m\"Model Used\"\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m<ipython-input-6-e402434bd3f9>\u001B[0m in \u001B[0;36mgradient_boosting\u001B[0;34m(df)\u001B[0m\n\u001B[1;32m     18\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     19\u001B[0m     \u001B[0;31m# Fit the random search model\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 20\u001B[0;31m     \u001B[0mclf_cv\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mfit\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mX_train\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0my_train\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     21\u001B[0m     \u001B[0my_pred\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mclf_cv\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mbest_estimator_\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mpredict\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mX_test\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     22\u001B[0m     \u001B[0mprint\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mclassification_report\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0my_test\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0my_pred\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/usr/local/lib/python3.9/site-packages/sklearn/utils/validation.py\u001B[0m in \u001B[0;36minner_f\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m     61\u001B[0m             \u001B[0mextra_args\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mlen\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;34m-\u001B[0m \u001B[0mlen\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mall_args\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     62\u001B[0m             \u001B[0;32mif\u001B[0m \u001B[0mextra_args\u001B[0m \u001B[0;34m<=\u001B[0m \u001B[0;36m0\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 63\u001B[0;31m                 \u001B[0;32mreturn\u001B[0m \u001B[0mf\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     64\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     65\u001B[0m             \u001B[0;31m# extra_args > 0\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/usr/local/lib/python3.9/site-packages/sklearn/model_selection/_search.py\u001B[0m in \u001B[0;36mfit\u001B[0;34m(self, X, y, groups, **fit_params)\u001B[0m\n\u001B[1;32m    839\u001B[0m                 \u001B[0;32mreturn\u001B[0m \u001B[0mresults\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    840\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 841\u001B[0;31m             \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_run_search\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mevaluate_candidates\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    842\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    843\u001B[0m             \u001B[0;31m# multimetric is determined here because in the case of a callable\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/usr/local/lib/python3.9/site-packages/sklearn/model_selection/_search.py\u001B[0m in \u001B[0;36m_run_search\u001B[0;34m(self, evaluate_candidates)\u001B[0m\n\u001B[1;32m   1631\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0m_run_search\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mevaluate_candidates\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1632\u001B[0m         \u001B[0;34m\"\"\"Search n_iter candidates from param_distributions\"\"\"\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 1633\u001B[0;31m         evaluate_candidates(ParameterSampler(\n\u001B[0m\u001B[1;32m   1634\u001B[0m             \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mparam_distributions\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mn_iter\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1635\u001B[0m             random_state=self.random_state))\n",
      "\u001B[0;32m/usr/local/lib/python3.9/site-packages/sklearn/model_selection/_search.py\u001B[0m in \u001B[0;36mevaluate_candidates\u001B[0;34m(candidate_params, cv, more_results)\u001B[0m\n\u001B[1;32m    793\u001B[0m                               n_splits, n_candidates, n_candidates * n_splits))\n\u001B[1;32m    794\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 795\u001B[0;31m                 out = parallel(delayed(_fit_and_score)(clone(base_estimator),\n\u001B[0m\u001B[1;32m    796\u001B[0m                                                        \u001B[0mX\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0my\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    797\u001B[0m                                                        \u001B[0mtrain\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mtrain\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mtest\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mtest\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/usr/local/lib/python3.9/site-packages/joblib/parallel.py\u001B[0m in \u001B[0;36m__call__\u001B[0;34m(self, iterable)\u001B[0m\n\u001B[1;32m   1044\u001B[0m                 \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_iterating\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_original_iterator\u001B[0m \u001B[0;32mis\u001B[0m \u001B[0;32mnot\u001B[0m \u001B[0;32mNone\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1045\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 1046\u001B[0;31m             \u001B[0;32mwhile\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mdispatch_one_batch\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0miterator\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   1047\u001B[0m                 \u001B[0;32mpass\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1048\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/usr/local/lib/python3.9/site-packages/joblib/parallel.py\u001B[0m in \u001B[0;36mdispatch_one_batch\u001B[0;34m(self, iterator)\u001B[0m\n\u001B[1;32m    859\u001B[0m                 \u001B[0;32mreturn\u001B[0m \u001B[0;32mFalse\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    860\u001B[0m             \u001B[0;32melse\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 861\u001B[0;31m                 \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_dispatch\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mtasks\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    862\u001B[0m                 \u001B[0;32mreturn\u001B[0m \u001B[0;32mTrue\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    863\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/usr/local/lib/python3.9/site-packages/joblib/parallel.py\u001B[0m in \u001B[0;36m_dispatch\u001B[0;34m(self, batch)\u001B[0m\n\u001B[1;32m    777\u001B[0m         \u001B[0;32mwith\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_lock\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    778\u001B[0m             \u001B[0mjob_idx\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mlen\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_jobs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 779\u001B[0;31m             \u001B[0mjob\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_backend\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mapply_async\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mbatch\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mcallback\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mcb\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    780\u001B[0m             \u001B[0;31m# A job can complete so quickly than its callback is\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    781\u001B[0m             \u001B[0;31m# called before we get here, causing self._jobs to\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/usr/local/lib/python3.9/site-packages/joblib/_parallel_backends.py\u001B[0m in \u001B[0;36mapply_async\u001B[0;34m(self, func, callback)\u001B[0m\n\u001B[1;32m    206\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0mapply_async\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mfunc\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mcallback\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;32mNone\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    207\u001B[0m         \u001B[0;34m\"\"\"Schedule a func to be run\"\"\"\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 208\u001B[0;31m         \u001B[0mresult\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mImmediateResult\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mfunc\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    209\u001B[0m         \u001B[0;32mif\u001B[0m \u001B[0mcallback\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    210\u001B[0m             \u001B[0mcallback\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mresult\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/usr/local/lib/python3.9/site-packages/joblib/_parallel_backends.py\u001B[0m in \u001B[0;36m__init__\u001B[0;34m(self, batch)\u001B[0m\n\u001B[1;32m    570\u001B[0m         \u001B[0;31m# Don't delay the application, to avoid keeping the input\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    571\u001B[0m         \u001B[0;31m# arguments in memory\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 572\u001B[0;31m         \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mresults\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mbatch\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    573\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    574\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0mget\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/usr/local/lib/python3.9/site-packages/joblib/parallel.py\u001B[0m in \u001B[0;36m__call__\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    260\u001B[0m         \u001B[0;31m# change the default number of processes to -1\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    261\u001B[0m         \u001B[0;32mwith\u001B[0m \u001B[0mparallel_backend\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_backend\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mn_jobs\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_n_jobs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 262\u001B[0;31m             return [func(*args, **kwargs)\n\u001B[0m\u001B[1;32m    263\u001B[0m                     for func, args, kwargs in self.items]\n\u001B[1;32m    264\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/usr/local/lib/python3.9/site-packages/joblib/parallel.py\u001B[0m in \u001B[0;36m<listcomp>\u001B[0;34m(.0)\u001B[0m\n\u001B[1;32m    260\u001B[0m         \u001B[0;31m# change the default number of processes to -1\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    261\u001B[0m         \u001B[0;32mwith\u001B[0m \u001B[0mparallel_backend\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_backend\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mn_jobs\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_n_jobs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 262\u001B[0;31m             return [func(*args, **kwargs)\n\u001B[0m\u001B[1;32m    263\u001B[0m                     for func, args, kwargs in self.items]\n\u001B[1;32m    264\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/usr/local/lib/python3.9/site-packages/sklearn/utils/fixes.py\u001B[0m in \u001B[0;36m__call__\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m    220\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0m__call__\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m*\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    221\u001B[0m         \u001B[0;32mwith\u001B[0m \u001B[0mconfig_context\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m**\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mconfig\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 222\u001B[0;31m             \u001B[0;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mfunction\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m",
      "\u001B[0;32m/usr/local/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\u001B[0m in \u001B[0;36m_fit_and_score\u001B[0;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, split_progress, candidate_progress, error_score)\u001B[0m\n\u001B[1;32m    596\u001B[0m             \u001B[0mestimator\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mfit\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mX_train\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mfit_params\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    597\u001B[0m         \u001B[0;32melse\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 598\u001B[0;31m             \u001B[0mestimator\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mfit\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mX_train\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0my_train\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mfit_params\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    599\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    600\u001B[0m     \u001B[0;32mexcept\u001B[0m \u001B[0mException\u001B[0m \u001B[0;32mas\u001B[0m \u001B[0me\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/usr/local/lib/python3.9/site-packages/sklearn/ensemble/_gb.py\u001B[0m in \u001B[0;36mfit\u001B[0;34m(self, X, y, sample_weight, monitor)\u001B[0m\n\u001B[1;32m    502\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    503\u001B[0m         \u001B[0;31m# fit the boosting stages\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 504\u001B[0;31m         n_stages = self._fit_stages(\n\u001B[0m\u001B[1;32m    505\u001B[0m             \u001B[0mX\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0my\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mraw_predictions\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0msample_weight\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_rng\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mX_val\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0my_val\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    506\u001B[0m             sample_weight_val, begin_at_stage, monitor)\n",
      "\u001B[0;32m/usr/local/lib/python3.9/site-packages/sklearn/ensemble/_gb.py\u001B[0m in \u001B[0;36m_fit_stages\u001B[0;34m(self, X, y, raw_predictions, sample_weight, random_state, X_val, y_val, sample_weight_val, begin_at_stage, monitor)\u001B[0m\n\u001B[1;32m    559\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    560\u001B[0m             \u001B[0;31m# fit next stage of trees\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 561\u001B[0;31m             raw_predictions = self._fit_stage(\n\u001B[0m\u001B[1;32m    562\u001B[0m                 \u001B[0mi\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mX\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0my\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mraw_predictions\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0msample_weight\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0msample_mask\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    563\u001B[0m                 random_state, X_csc, X_csr)\n",
      "\u001B[0;32m/usr/local/lib/python3.9/site-packages/sklearn/ensemble/_gb.py\u001B[0m in \u001B[0;36m_fit_stage\u001B[0;34m(self, i, X, y, raw_predictions, sample_weight, sample_mask, random_state, X_csc, X_csr)\u001B[0m\n\u001B[1;32m    212\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    213\u001B[0m             \u001B[0mX\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mX_csr\u001B[0m \u001B[0;32mif\u001B[0m \u001B[0mX_csr\u001B[0m \u001B[0;32mis\u001B[0m \u001B[0;32mnot\u001B[0m \u001B[0;32mNone\u001B[0m \u001B[0;32melse\u001B[0m \u001B[0mX\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 214\u001B[0;31m             tree.fit(X, residual, sample_weight=sample_weight,\n\u001B[0m\u001B[1;32m    215\u001B[0m                      check_input=False)\n\u001B[1;32m    216\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/usr/local/lib/python3.9/site-packages/sklearn/tree/_classes.py\u001B[0m in \u001B[0;36mfit\u001B[0;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001B[0m\n\u001B[1;32m   1250\u001B[0m         \"\"\"\n\u001B[1;32m   1251\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 1252\u001B[0;31m         super().fit(\n\u001B[0m\u001B[1;32m   1253\u001B[0m             \u001B[0mX\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0my\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1254\u001B[0m             \u001B[0msample_weight\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0msample_weight\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/usr/local/lib/python3.9/site-packages/sklearn/tree/_classes.py\u001B[0m in \u001B[0;36mfit\u001B[0;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001B[0m\n\u001B[1;32m    392\u001B[0m                                            min_impurity_split)\n\u001B[1;32m    393\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 394\u001B[0;31m         \u001B[0mbuilder\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mbuild\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mtree_\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mX\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0my\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0msample_weight\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    395\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    396\u001B[0m         \u001B[0;32mif\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mn_outputs_\u001B[0m \u001B[0;34m==\u001B[0m \u001B[0;36m1\u001B[0m \u001B[0;32mand\u001B[0m \u001B[0mis_classifier\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler, Normalizer,LabelEncoder\n",
    "\n",
    "def encoder(ya, yb):\n",
    "    le = LabelEncoder()\n",
    "    le.fit(ya)\n",
    "    y_enc = le.transform(yb)\n",
    "    return y_enc\n",
    "\n",
    "def scaler(a,b):\n",
    "    s = StandardScaler().fit(a)\n",
    "    return s.transform(b)\n",
    "\n",
    "def normalizer(a,b):\n",
    "    s = Normalizer().fit(a)\n",
    "    return s.transform(b)\n",
    "\n",
    "\n",
    "def compute_max_corr(df):\n",
    "    y = encode_y(df[df.columns[-1]])\n",
    "    y = pd.Series(y)\n",
    "    corr = df[df.columns[:-1]].corrwith(y)\n",
    "    return np.max(np.absolute(corr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_features(df):\n",
    "    label=df.columns[-1]\n",
    "    features=df.columns[:-1]\n",
    "    computed_features=[]\n",
    "\n",
    "    MajorityClassSize=df.groupby(by=label).size().max()\n",
    "    computed_features.append(MajorityClassSize)\n",
    "\n",
    "    MaxNominalAttDistinctValues=df[features].select_dtypes(exclude=[np.number]).nunique().values.max()#must check this\n",
    "    computed_features.append(MaxNominalAttDistinctValues)\n",
    "\n",
    "    MinorityClassSize=df.groupby(by=label).size().min()\n",
    "    computed_features.append(MinorityClassSize)\n",
    "\n",
    "    NumberOfClasses=df[label].unique().shape[0]\n",
    "    computed_features.append(NumberOfClasses)\n",
    "\n",
    "    NumberOfFeatures=df.shape[1]-1\n",
    "    computed_features.append(NumberOfFeatures)\n",
    "\n",
    "    NumberOfInstances=df.shape[0]\n",
    "    computed_features.append(NumberOfInstances)\n",
    "\n",
    "    NumberOfInstancesWithMissingValues=df.isnull().any(axis=1).sum()\n",
    "    computed_features.append(NumberOfInstancesWithMissingValues)\n",
    "\n",
    "    NumberOfMissingValues=df.isnull().all(axis=1).sum()\n",
    "    computed_features.append(NumberOfMissingValues)\n",
    "\n",
    "    NumberOfNumericFeatures=df[features].select_dtypes([np.number]).shape[1]\n",
    "    computed_features.append(NumberOfNumericFeatures)\n",
    "\n",
    "    NumberOfSymbolicFeatures=df[features].select_dtypes(exclude=[np.number]).shape[1]#must check this\n",
    "    computed_features.append(NumberOfSymbolicFeatures)\n",
    "\n",
    "    max_corr=compute_max_corr(df)\n",
    "    computed_features.append(max_corr)\n",
    "\n",
    "    return np.array(computed_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}